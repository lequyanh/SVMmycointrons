#!/bin/bash

PYTHON=/home/anhvu/anaconda3/envs/mykointron/bin/python

ASSEMBLIES_LOC="/home/anhvu/Desktop/mykointrons-data"
SHROOM_NAMES_ALL="/home/anhvu/PycharmProjects/mycointrons/ascomycotas.txt"
SHROOM_SPECIES="ascomycota"

# ----------- CREATE FALSE SPLICE SITE WINDOWS FOR EACH SHROOM (INTERGENIC GT/AG WINDOWS VERSION)-----------------
#GFF_LOC=/home/anhvu/Desktop/ascomycota-data/GFFS/
#OUTPUT_LOC="/home/anhvu/Desktop/mykointrons-data/new-sequences/"
#
#while read shroom; do
#  echo "${shroom}"
#
#  if [ -f "$OUTPUT_LOC/${shroom}/${shroom}-acceptor-false.fasta" ]
#  then
#    continue
#  fi
#
#  shroom_assembly="$ASSEMBLIES_LOC/data/Assembly/${shroom}_AssemblyScaffolds.fasta"
#
#  find $GFF_LOC -name "${shroom}*.gff" -print0 |
#  xargs -I{} python ../tools/gff.py "${shroom}" "${shroom_assembly}" {} "$OUTPUT_LOC/${shroom}"
#
#  mv "${shroom}-acceptor-false.fasta" $OUTPUT_LOC/"${shroom}"/
#  mv "${shroom}-donor-false.fasta" $OUTPUT_LOC/"${shroom}"/
#
#done < $SHROOM_NAMES_ALL

# ----------- CREATE FALSE SPLICE SITE WINDOWS FOR EACH SHROOM (TAKE-GT/AG-WINDOWS-FROM-ANYWHERE VERSION)-----------------
 # Also an output folder - each shroom sub-directory will have a fasta file with false introns.
INTRON_LOC="/home/anhvu/Desktop/mykointrons-data/new-sequences"
EXAMPLE_LIMIT=50000
WINDOW_DIAMETER=200

function generate_false_splice_site_windows() {
    while read shroom; do
      $PYTHON splicesite/extract_false_splice_sites.py "${shroom}" "${ASSEMBLIES_LOC}/data/Assembly" ${INTRON_LOC} ${EXAMPLE_LIMIT} ${WINDOW_DIAMETER}
    done <${SHROOM_NAMES_ALL}
}

# ----------- SPLITS MUSHROOM CLASSES TO 4 SETS -----------------
function split_species_to_train_test_sets() {
    split_dir="shroom_split/$SHROOM_SPECIES/"
    mkdir -p $split_dir

    INT_TRAIN_NAMES="$split_dir/intron_train_names.txt"
    INT_TEST_NAMES="$split_dir/intron_test_names.txt"
    SPLICE_TRAIN_NAMES="$split_dir/splice_sites_train_names.txt"
    SPLICE_TEST_NAMES="$split_dir/splice_sites_test_names.txt"

    no_shrooms=$(wc -l < ${SHROOM_NAMES_ALL})
    train_size=$(( no_shrooms / 2 * 6 / 10 ))
    test_size=$(( no_shrooms / 2 * 4 / 10 ))

    echo "Number of mushrooms ${no_shrooms}. Splitting to 2 train lists with ${train_size} and 2 test lists with ${test_size} classes"

    {
        head -n ${train_size} >  $SPLICE_TRAIN_NAMES
        head -n ${test_size} > $SPLICE_TEST_NAMES
        head -n ${train_size} > $INT_TRAIN_NAMES
        cat >  $INT_TEST_NAMES
    } < ${SHROOM_NAMES_ALL}
}

# ----------- FOR MUSHROOMS USED FOR SPLICE SITE TRAINING/TESTING, GENERATE WINDOWS -----------------
# This should create 2 folders - test and train each containing donor and acceptor windows from a particular shroom
splicesite_dataloc="../data/$SHROOM_SPECIES"
mkdir -p $splicesite_dataloc/train/donor/
mkdir -p $splicesite_dataloc/train/acceptor/
mkdir -p $splicesite_dataloc/test/donor/
mkdir -p $splicesite_dataloc/test/acceptor/

function create_train_test_csvs() {
    echo "Generating train and test splice site windows for mushroom $SHROOM_SPECIES. Data will be saved to $splicesite_dataloc"

    shroom_names=$1
    train_test=$2
    for shroom in $(<"$shroom_names")
    do
        $PYTHON ./splicesite/create_splice_site_windows.py $ASSEMBLIES_LOC "${shroom}" 200 200 200 200 $splicesite_dataloc "${train_test}"
    done
}

# ----------- MIX WINDOWS FROM ALL MUSHROOMS AND SAMPLE A SINGLE TRAIN/TEST CSV FILE -----------------
function mix_and_merge_windows_to_single_file() {
    NO_TRAIN=400000
    SHUFFLED_DONOR_SITE_TRAINSET_NAME='shuff_aggreg_donor_site_train.csv'
    SHUFFLED_ACCEPTOR_SITE_TRAINSET_NAME='shuff_aggreg_acceptor_site_train.csv'
    bash splicesite/merge_shuffle_datasets.sh $splicesite_dataloc/train/donor $NO_TRAIN $SHUFFLED_DONOR_SITE_TRAINSET_NAME ./
    bash splicesite/merge_shuffle_datasets.sh $splicesite_dataloc/train/acceptor $NO_TRAIN $SHUFFLED_ACCEPTOR_SITE_TRAINSET_NAME ./
    mv $SHUFFLED_DONOR_SITE_TRAINSET_NAME $splicesite_dataloc/train
    mv $SHUFFLED_ACCEPTOR_SITE_TRAINSET_NAME $splicesite_dataloc/train

    NO_TEST=500000
    SHUFFLED_DONOR_SITE_TESTSET_NAME='shuff_aggreg_donor_site_test.csv'
    SHUFFLED_ACCEPTOR_SITE_TESTSET_NAME='shuff_aggreg_acceptor_site_test.csv'
    bash splicesite/merge_shuffle_datasets.sh $splicesite_dataloc/test/donor $NO_TEST $SHUFFLED_DONOR_SITE_TESTSET_NAME ./
    bash splicesite/merge_shuffle_datasets.sh $splicesite_dataloc/test/acceptor $NO_TEST $SHUFFLED_ACCEPTOR_SITE_TESTSET_NAME ./
    mv $SHUFFLED_DONOR_SITE_TESTSET_NAME $splicesite_dataloc/test
    mv $SHUFFLED_ACCEPTOR_SITE_TESTSET_NAME $splicesite_dataloc/test
}

# ===================================================================================================
# 1. step
generate_false_splice_site_windows
# 2. step
split_species_to_train_test_sets
# 3. step
create_train_test_csvs $SPLICE_TRAIN_NAMES train
create_train_test_csvs $SPLICE_TEST_NAMES test
# 4. step
mix_and_merge_windows_to_single_file
