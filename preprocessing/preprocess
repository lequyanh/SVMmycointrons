#!/bin/bash

PYTHON=/home/anhvu/anaconda3/envs/mykointron/bin/python

ASSEMBLIES_LOC=~/Desktop/mykointrons-data
SHROOM_NAMES_ALL=../ascomycotas.txt
SHROOM_SPECIES=ascomycota
GFF_LOC=/home/anhvu/Desktop/ascomycota-data/GFFS/

# ----------- CREATE FALSE SPLICE SITE WINDOWS FOR EACH SHROOM -----------------
#OUTPUT_LOC="/home/anhvu/Desktop/mykointrons-data/new-sequences/"
#
#while read shroom; do
#  echo "${shroom}"
#
#  if [ -f "$OUTPUT_LOC/${shroom}/${shroom}-acceptor-false.fasta" ]
#  then
#    continue
#  fi
#
#  shroom_assembly="$ASSEMBLIES_LOC/data/Assembly/${shroom}_AssemblyScaffolds.fasta"
#
#  find $GFF_LOC -name "${shroom}*.gff" -print0 |
#  xargs -I{} python ../tools/gff.py "${shroom}" "${shroom_assembly}" {} "$OUTPUT_LOC/${shroom}"
#
#  mv "${shroom}-acceptor-false.fasta" $OUTPUT_LOC/"${shroom}"/
#  mv "${shroom}-donor-false.fasta" $OUTPUT_LOC/"${shroom}"/
#
#done < $SHROOM_NAMES_ALL

# ----------- SPLITS MUSHROOM CLASSES TO 4 SETS -----------------
split_dir="shroom_split/$SHROOM_SPECIES/"
mkdir -p $split_dir

INT_TRAIN_NAMES="$split_dir/intron_train_names.txt"
INT_TEST_NAMES="$split_dir/intron_test_names.txt"
SPLICE_TRAIN_NAMES="$split_dir/splice_sites_train_names.txt"
SPLICE_TEST_NAMES="$split_dir/splice_sites_test_names.txt"

no_shrooms=$(wc -l < ${SHROOM_NAMES_ALL})
train_size=$(( no_shrooms / 2 * 6 / 10 ))
test_size=$(( no_shrooms / 2 * 4 / 10 ))

echo "Number of mushrooms ${no_shrooms}. Splitting to 2 train lists with ${train_size} and 2 test lists with ${test_size} classes"

{
    head -n ${train_size} >  $SPLICE_TRAIN_NAMES
    head -n ${test_size} > $SPLICE_TEST_NAMES
    head -n ${train_size} > $INT_TRAIN_NAMES
    cat >  $INT_TEST_NAMES
} < ${SHROOM_NAMES_ALL}

# ----------- FOR MUSHROOMS USED FOR SPLICE SITE TRAINING/TESTING, GENERATE WINDOWS -----------------
# This should create 2 folders - test and train each containing donor and acceptor windows from a particular shroom
splicesite_dataloc="../data/$SHROOM_SPECIES"
mkdir -p $splicesite_dataloc/train/donor/
mkdir -p $splicesite_dataloc/train/acceptor/
mkdir -p $splicesite_dataloc/test/donor/
mkdir -p $splicesite_dataloc/test/acceptor/

echo "Generating train and test splice site windows for mushroom $SHROOM_SPECIES. Data will be saved to $splicesite_dataloc"

function create_train_test_csvs() {
    shroom_names=$1
    train_test=$2
    for shroom in $(<"$shroom_names")
    do
        $PYTHON ./splicesite/create_splice_site_windows.py $ASSEMBLIES_LOC "${shroom}" 150 150 150 150 $splicesite_dataloc "${train_test}"
    done
}

create_train_test_csvs $SPLICE_TRAIN_NAMES train
create_train_test_csvs $SPLICE_TEST_NAMES test

# ----------- MIX WINDOWS FROM ALL MUSHROOMS AND SAMPLE A SINGLE TRAIN/TEST CSV FILE -----------------
NO_TRAIN=400000
SHUFFLED_DONOR_SITE_TRAINSET_NAME='shuff_aggreg_donor_site_train.csv'
SHUFFLED_ACCEPTOR_SITE_TRAINSET_NAME='shuff_aggreg_acceptor_site_train.csv'
bash splicesite/merge_shuffle_datasets.sh $splicesite_dataloc/train/donor $NO_TRAIN $SHUFFLED_DONOR_SITE_TRAINSET_NAME ./
bash splicesite/merge_shuffle_datasets.sh $splicesite_dataloc/train/acceptor $NO_TRAIN $SHUFFLED_ACCEPTOR_SITE_TRAINSET_NAME ./
mv $SHUFFLED_DONOR_SITE_TRAINSET_NAME $splicesite_dataloc/train
mv $SHUFFLED_ACCEPTOR_SITE_TRAINSET_NAME $splicesite_dataloc/train

NO_TEST=500000
SHUFFLED_DONOR_SITE_TESTSET_NAME='shuff_aggreg_donor_site_test.csv'
SHUFFLED_ACCEPTOR_SITE_TESTSET_NAME='shuff_aggreg_acceptor_site_test.csv'
bash splicesite/merge_shuffle_datasets.sh $splicesite_dataloc/test/donor $NO_TEST $SHUFFLED_DONOR_SITE_TESTSET_NAME ./
bash splicesite/merge_shuffle_datasets.sh $splicesite_dataloc/test/acceptor $NO_TEST $SHUFFLED_ACCEPTOR_SITE_TESTSET_NAME ./
mv $SHUFFLED_DONOR_SITE_TESTSET_NAME $splicesite_dataloc/test
mv $SHUFFLED_ACCEPTOR_SITE_TESTSET_NAME $splicesite_dataloc/test
